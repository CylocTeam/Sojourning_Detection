{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data():\n",
    "    # read data for testing\n",
    "    data = pd.read_csv(\"../data/a02_p3.csv\")\n",
    "    data.timestamp = pd.to_datetime(data.timestamp, format='%H:%M:%S.%f')\n",
    "\n",
    "    acc_x = data.x.to_numpy()\n",
    "    acc_y = data.y.to_numpy()\n",
    "    acc_z = data.z.to_numpy()\n",
    "    # timestamp = data.timestamp.to_numpy()\n",
    "\n",
    "    # is_stay, stay_times, stay_durations = find_stays(df.x, df.y, df.z, df.timestamp, params)\n",
    "    # find_stays(df.x, df.y, df.z, df.timestamp, params)\n",
    "\n",
    "    # unpack\n",
    "    df = pd.DataFrame({'x': acc_x, 'y': acc_y, 'z': acc_z}, index = data.timestamp)\n",
    "    df['norm'] = df.apply(lambda row: np.sqrt(row.x**2 + row.y**2 + row.z**2), axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate Class"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 25 #[Hz]\n",
    "params = {\"win_size_sec\": 3,\n",
    "\"ecdf_diff_th\": 0.01,\n",
    "\"var_th\": 0.05,\n",
    "\"abrupt_filt_time_const\": 10,\n",
    "\"abrupt_pctg_th\": 0.2,\n",
    "\"min_stay_duration\": 1,\n",
    "\"max_time_gap_msec\": 1e3 * 5 / fs,\n",
    "\"max_section_gap_minutes\": 7,\n",
    "\"max_time_gap_pctl\": 60}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# methods"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_sample_rate(time_diffs,params):\n",
    "    return (time_diffs.\n",
    "        where(time_diffs <= np.percentile(time_diffs[time_diffs.notnull()], params[\"max_time_gap_pctl\"])).\n",
    "        map(lambda x: 1e9/x).\n",
    "        mean())\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sections_idx(time_diffs_ns, params):\n",
    "    max_section_gap = np.array(params[\"max_section_gap_minutes\"], dtype='timedelta64[m]')\n",
    "\n",
    "    max_section_gap_ns = max_section_gap.astype('timedelta64[ns]').astype('float64')\n",
    "    section_idxs_list = time_diffs[time_diffs_ns > max_section_gap_ns].index.to_list()\n",
    "\n",
    "    section_idxs_list.insert(0, time_diffs_ns.index[0])\n",
    "    section_idxs_list.append(time_diffs_ns.index[-1])\n",
    "    return pd.to_datetime(section_idxs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_var_th(acc_abs,win_size_smp,MAX_HIST_BINS,params):\n",
    "    acc_rollvar = acc_abs.rolling(win_size_smp, min_periods=0).var()\n",
    "    acc_rollvar = acc_rollvar[acc_rollvar.notnull()]\n",
    "    hist, bin_edges = np.histogram(acc_rollvar,bins=MAX_HIST_BINS)\n",
    "    mvr_epdf = hist / sum(hist); # normalize to pdf\n",
    "    knee_th = bin_edges[np.argwhere(mvr_epdf < params[\"ecdf_diff_th\"])[-1]]\n",
    "    if not knee_th.size:\n",
    "        knee_th = params[\"var_th\"]\n",
    "    return float(min([params[\"var_th\"], knee_th]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_abrupt_movements(is_stay_raw, abrupt_filt_size, params):\n",
    "    soft_stay = is_stay_raw.rolling(abrupt_filt_size, min_periods=0).mean()\n",
    "    return (soft_stay > params[\"abrupt_pctg_th\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_filters_size(time_diffs,params):\n",
    "    fs = avg_sample_rate(time_diffs,params)\n",
    "    sec2smp = lambda sec: np.floor(sec*fs).astype('int')\n",
    "    win_size_smp = sec2smp(params[\"win_size_sec\"])\n",
    "    abrupt_filt_size = sec2smp(params[\"abrupt_filt_time_const\"])\n",
    "    return win_size_smp, abrupt_filt_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stay_raw(df, win_size_smp,var_th, NUM_DIMS):\n",
    "    df_rollvar = df.rolling(win_size_smp, min_periods=0).var()\n",
    "    is_axis_stay = df_rollvar[[\"x\",\"y\",\"z\"]] < var_th/NUM_DIMS\n",
    "    is_norm_stay = df_rollvar[\"norm\"] < var_th\n",
    "    is_stay = is_axis_stay.all(axis = 1) & is_norm_stay\n",
    "    # is_stay.name = \"is_stay\"\n",
    "    return is_stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_time_tags(df):\n",
    "    toggle_indicator = df.is_stay.astype(int).diff()\n",
    "    start_times = toggle_indicator[toggle_indicator == 1].index\n",
    "    end_times = toggle_indicator[toggle_indicator == -1].index\n",
    "    return start_times, end_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definitions\n",
    "df = import_data()\n",
    "df = df.sort_index()\n",
    "df['diff_ns'] = np.insert(np.diff(df.index.to_numpy().astype('float')),0, None)\n",
    "df['is_stay'] = True\n",
    "    \n",
    "MAX_HIST_BINS = int(1e4)\n",
    "NUM_DIMS = 3 # {x y z}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DatetimeIndex(['1900-01-01 15:04:51.552000'], dtype='datetime64[ns]', freq=None)"
     },
     "metadata": {},
     "execution_count": 196
    }
   ],
   "source": [
    "# calc params in sample (ctor)\n",
    "\n",
    "win_size_smp, abrupt_filt_size = convert_filters_size(df['diff_ns'],params)\n",
    "var_th = update_var_th(df[\"norm\"],win_size_smp,MAX_HIST_BINS,params) # optionally update var_th\n",
    "\n",
    "# split to sections (main)\n",
    "sections_times = find_sections_idx(df['diff_ns'], params) #find sections in large sequence of data seperated by max_section_gap_minutes\n",
    "\n",
    "sec=0\n",
    "sections_times[sec:sec+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through each section and decide isStay\n",
    "for sec in range(len(sections_times)-1):\n",
    "    is_stay = check_stay_raw(df.loc[sections_times[sec]:sections_times[sec+1]].iloc[:-1], #excluding left endpoint\n",
    "    win_size_smp, var_th, NUM_DIMS)\n",
    "    df.loc[is_stay.index, \"is_stay\"] = is_stay\n",
    "\n",
    "# df.is_stay = check_stay_raw(df, win_size_smp, var_th, NUM_DIMS)\n",
    "# df.is_stay.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter abrupt movements\n",
    "df.is_stay = filter_abrupt_movements(df.is_stay, abrupt_filt_size, params)\n",
    "# df.is_stay.sum()\n",
    "\n",
    "# force sectioning\n",
    "df.is_stay.loc[sections_times] = False\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find start & end times\n",
    "start_times, end_times = find_time_tags(df)\n",
    "stays = pd.DataFrame({\"start_times\": start_times, \"end_times\": end_times})\n",
    "stays['duration'] = stays.apply(lambda row: row[\"end_times\"] - row[\"start_times\"], axis=1)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                    start_times                     end_times        duration\n2 1900-01-01 15:05:45.559200960 1900-01-01 15:07:32.253426856 00:01:46.694225\n3 1900-01-01 15:07:50.095805840 1900-01-01 15:09:19.107674089 00:01:29.011868\n4 1900-01-01 15:09:21.948052807 1900-01-01 16:04:51.552000000 00:55:29.603947\n6 1900-01-01 16:05:45.559200960 1900-01-01 16:07:32.253426856 00:01:46.694225\n7 1900-01-01 16:07:50.095805840 1900-01-01 16:09:19.107674089 00:01:29.011868",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>start_times</th>\n      <th>end_times</th>\n      <th>duration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>1900-01-01 15:05:45.559200960</td>\n      <td>1900-01-01 15:07:32.253426856</td>\n      <td>00:01:46.694225</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1900-01-01 15:07:50.095805840</td>\n      <td>1900-01-01 15:09:19.107674089</td>\n      <td>00:01:29.011868</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1900-01-01 15:09:21.948052807</td>\n      <td>1900-01-01 16:04:51.552000000</td>\n      <td>00:55:29.603947</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1900-01-01 16:05:45.559200960</td>\n      <td>1900-01-01 16:07:32.253426856</td>\n      <td>00:01:46.694225</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1900-01-01 16:07:50.095805840</td>\n      <td>1900-01-01 16:09:19.107674089</td>\n      <td>00:01:29.011868</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 204
    }
   ],
   "source": [
    "# cancle short sojourns\n",
    "if stays.empty:\n",
    "    pass #return stays\n",
    "\n",
    "stay_long_enough = stays['duration'] > pd.to_timedelta(params[\"min_stay_duration\"], unit = 'm')\n",
    "stays = stays[stay_long_enough]\n",
    "stays\n",
    "\n",
    "# stay_times(is_short_stay,:) = [];\n",
    "# stay_durations(is_short_stay,:) = [];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0"
     },
     "metadata": {},
     "execution_count": 201
    }
   ],
   "source": [
    "df.is_stay.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df.index.to_series().diff()\n",
    "s\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}